# üß† Web Scraping y An√°lisis de Productos

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/Licencia-Acad√©mica-lightgrey.svg)]()
[![Status](https://img.shields.io/badge/Estado-En%20Desarrollo-yellow.svg)]()
[![DOI](https://img.shields.io/badge/DOI-Zenodo-blue.svg)](https://doi.org/10.XXXX/zenodo.XXXXXXX)

---

## üìö Tabla de Contenidos

1. [Autores](#1-autores)  
2. [Resumen del Proyecto](#2-resumen-del-proyecto)  
3. [Estructura del Repositorio](#3-estructura-del-repositorio)  
4. [Metodolog√≠a de Trabajo](#4-metodolog√≠a-de-trabajo)  
5. [Instrucciones de Uso](#5-instrucciones-de-uso)  
6. [Par√°metros y Personalizaci√≥n](#6-par√°metros-y-personalizaci√≥n)  
7. [Resultados Generados](#7-resultados-generados)  
8. [DOI del Dataset](#8-doi-del-dataset)  
9. [Licencia](#9-licencia)

---

## 1. Autores

- **Pedro G√≥mez Revilla**  
- **Andrea Isabel Espada Murguia**

---

## 2. Resumen del Proyecto

El presente proyecto tiene como objetivo la **obtenci√≥n, procesamiento y an√°lisis de datos de productos** mediante t√©cnicas de **web scraping** automatizado.  

Se emplean herramientas de **Python** y librer√≠as de automatizaci√≥n (como *Selenium*) para recopilar informaci√≥n de distintas fuentes web, almacenar los datos en formato CSV

El flujo de trabajo abarca desde la **recolecci√≥n autom√°tica de URLs**, pasando por la **extracci√≥n de datos e im√°genes**.

---
## 3. Estructura del Repositorio

El repositorio se organiza de la siguiente manera:

### Archivos en la ra√≠z del proyecto

- **.gitignore** ‚Üí Define los archivos y carpetas que no deben incluirse en el control de versiones.  
- **README.md** ‚Üí Contiene la informaci√≥n general y documentaci√≥n del proyecto.  
- **source/** ‚Üí Carpeta principal que agrupa el c√≥digo fuente y los datos generados o recopilados.

---

### Contenido de la carpeta `source/`

- **dataset/** ‚Üí Contiene los resultados obtenidos del proceso de scraping y an√°lisis.
  - **graficos/** ‚Üí Carpeta donde se almacenan los gr√°ficos generados a partir de los datos del CSV.  
  - **images/** ‚Üí Carpeta con las im√°genes descargadas de los productos procesados.  
  - **productos.csv** ‚Üí Archivo que almacena la informaci√≥n estructurada extra√≠da mediante web scraping.

- **environment.yml** ‚Üí Archivo que define el entorno de trabajo de Python, incluyendo las librer√≠as y versiones necesarias para ejecutar el proyecto.  
- **geckodriver.exe** ‚Üí Ejecutable requerido por Selenium para la automatizaci√≥n del navegador Firefox.  
- **obtencion_datos.py** ‚Üí Script encargado de recopilar las URLs de los productos que posteriormente ser√°n procesados.  
- **web_scraping.py** ‚Üí Script principal de extracci√≥n de datos. Utiliza las URLs obtenidas para recolectar informaci√≥n e im√°genes de los productos, y genera el archivo `productos.csv`.  
- **crear_graficas.py** ‚Üí Script que analiza el archivo CSV generado y produce visualizaciones gr√°ficas a partir de los datos recopilados.

---

## 4. Metodolog√≠a de Trabajo

1. **Obtenci√≥n de URLs**  
   Se utiliza `obtencion_datos.py` para recopilar enlaces de productos desde una fuente web determinada.  

2. **Extracci√≥n de Datos (Web Scraping)**  
   El script `web_scraping.py` accede a las URLs, extrae la informaci√≥n relevante de cada producto y descarga sus im√°genes.  

3. **Generaci√≥n de Dataset**  
   Los datos se consolidan en el archivo `productos.csv` dentro de la carpeta `dataset/`.  

---

## 5. Instrucciones de Uso

### 5.1 Crear el entorno de ejecuci√≥n

Para preparar el entorno Python, ejecutar:

```bash
conda env create -f environment.yml
conda activate scraping_project
```
5.2 Realizar el scraping

```bash

python web_scraping.py
```

Crea el archivo productos.csv y descarga las im√°genes en dataset/images/.

## 6. Par√°metros y Personalizaci√≥n

Actualmente, los scripts no requieren par√°metros externos para su ejecuci√≥n.  
No obstante, el usuario puede personalizar distintos aspectos del proyecto seg√∫n sus necesidades:

- **Fuente o dominio de las URLs:** permite definir desde qu√© p√°gina web se extraer√°n los datos.  
- **N√∫mero de productos a analizar:** configurable para ajustar la cantidad de elementos procesados.  
- **Formato de salida del dataset o de las gr√°ficas:** se puede modificar el tipo de archivo o el estilo visual de las representaciones.

Estas configuraciones se encuentran dentro de los propios scripts Python y pueden adaptarse f√°cilmente editando las variables definidas al inicio de cada archivo.

---

## 7. Resultados Generados

El proyecto produce los siguientes resultados principales:

- **`productos.csv`** ‚Üí Contiene los datos estructurados extra√≠dos mediante web scraping.  
- **`images/`** ‚Üí Carpeta que almacena las im√°genes descargadas de los productos procesados.  
- **`graficos/`** ‚Üí Carpeta con los gr√°ficos generados autom√°ticamente a partir del archivo CSV.

Estos recursos permiten **analizar el comportamiento del mercado y las caracter√≠sticas de los productos** de manera visual e interactiva.

---

## 8. DOI del Dataset

El dataset final ha sido publicado en **Zenodo**, disponible en el siguiente enlace:

üîó **[https://doi.org/10.5281/zenodo.17566073](https://doi.org/10.5281/zenodo.17566073)**  

---

## 9. Licencia

Este proyecto se distribuye con fines **acad√©micos y de investigaci√≥n**.  
El c√≥digo puede ser utilizado, modificado o extendido citando la fuente original y respetando las licencias de las herramientas utilizadas.

---
