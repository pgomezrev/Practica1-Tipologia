# ðŸ§  Web Scraping y AnÃ¡lisis de Productos

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/Licencia-AcadÃ©mica-lightgrey.svg)]()
[![Status](https://img.shields.io/badge/Estado-En%20Desarrollo-yellow.svg)]()
[![DOI](https://img.shields.io/badge/DOI-Zenodo-blue.svg)](https://doi.org/10.XXXX/zenodo.XXXXXXX)

---

## ðŸ“š Tabla de Contenidos

1. [Autores](#1-autores)  
2. [Resumen del Proyecto](#2-resumen-del-proyecto)  
3. [Estructura del Repositorio](#3-estructura-del-repositorio)  
4. [MetodologÃ­a de Trabajo](#4-metodologÃ­a-de-trabajo)  
5. [Instrucciones de Uso](#5-instrucciones-de-uso)  
6. [ParÃ¡metros y PersonalizaciÃ³n](#6-parÃ¡metros-y-personalizaciÃ³n)  
7. [Resultados Generados](#7-resultados-generados)  
8. [DOI del Dataset](#8-doi-del-dataset)  
9. [Licencia](#9-licencia)

---

## 1. Autores

- **Pedro GÃ³mez Revilla**  
- **Andrea Isabel Espada Murguia**

---

## 2. Resumen del Proyecto

El presente proyecto tiene como objetivo la **obtenciÃ³n, procesamiento y anÃ¡lisis de datos de productos** mediante tÃ©cnicas de **web scraping** automatizado.  

Se emplean herramientas de **Python** y librerÃ­as de automatizaciÃ³n (como *Selenium*) para recopilar informaciÃ³n de distintas fuentes web, almacenar los datos en formato CSV

El flujo de trabajo abarca desde la **recolecciÃ³n automÃ¡tica de URLs**, pasando por la **extracciÃ³n de datos e imÃ¡genes**.

---

## 3. Estructura del Repositorio

â”œâ”€â”€ .gitignore # Define los archivos que no deben subirse al repositorio
â”œâ”€â”€ README.md # InformaciÃ³n general del proyecto
â””â”€â”€ source/ # Carpeta principal del cÃ³digo fuente y los datos
â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ graficos/ # GrÃ¡ficos generados a partir del CSV
â”‚ â”œâ”€â”€ images/ # ImÃ¡genes de los productos procesados
â”‚ â””â”€â”€ productos.csv # Datos extraÃ­dos mediante web scraping
â”‚
â”œâ”€â”€ environment.yml # ConfiguraciÃ³n del entorno Python (librerÃ­as y dependencias)
â”œâ”€â”€ geckodriver.exe # Ejecutable necesario para Selenium
â”œâ”€â”€ obtencion_datos.py # Obtiene las URLs de los productos a procesar
â”œâ”€â”€ web_scraping.py # Extrae informaciÃ³n e imÃ¡genes de los productos y genera el CSV
â””â”€â”€ crear_graficas.py # Genera grÃ¡ficos a partir del CSV generado


---

## 4. MetodologÃ­a de Trabajo

1. **ObtenciÃ³n de URLs**  
   Se utiliza `obtencion_datos.py` para recopilar enlaces de productos desde una fuente web determinada.  

2. **ExtracciÃ³n de Datos (Web Scraping)**  
   El script `web_scraping.py` accede a las URLs, extrae la informaciÃ³n relevante de cada producto y descarga sus imÃ¡genes.  

3. **GeneraciÃ³n de Dataset**  
   Los datos se consolidan en el archivo `productos.csv` dentro de la carpeta `dataset/`.  

---

## 5. Instrucciones de Uso

### 5.1 Crear el entorno de ejecuciÃ³n

Para preparar el entorno Python, ejecutar:

```bash
conda env create -f environment.yml
conda activate scraping_project

5.2 Realizar el scraping

python web_scraping.py

Crea el archivo productos.csv y descarga las imÃ¡genes en dataset/images/.

6. ParÃ¡metros y PersonalizaciÃ³n

Actualmente, los scripts no requieren parÃ¡metros externos.
Sin embargo, el usuario puede personalizar:

    La fuente o dominio de las URLs.

    El nÃºmero de productos a analizar.

    El formato de salida del dataset o de las grÃ¡ficas.

Estas configuraciones se encuentran dentro de los propios scripts Python.

7. Resultados Generados

El proyecto produce los siguientes resultados:

    Archivo productos.csv con los datos estructurados.

    Carpeta images/ con las imÃ¡genes de cada producto.

Estos recursos permiten analizar el comportamiento del mercado y las caracterÃ­sticas de los productos de forma visual e interactiva.

8. DOI del Dataset

El dataset final ha sido publicado en Zenodo, disponible en el siguiente enlace:

ðŸ”— https://doi.org/10.XXXX/zenodo.XXXXXXX

9. Licencia

Este proyecto se distribuye con fines acadÃ©micos y de investigaciÃ³n.
El cÃ³digo puede ser utilizado, modificado o extendido citando la fuente original y respetando las licencias de las herramientas utilizadas.
